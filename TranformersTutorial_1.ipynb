{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TranformersTutorial_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO6F+ULWz3q+FKVpyP0GINF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TahaBinhuraib/Transformers_Notes/blob/main/TranformersTutorial_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports and downloads\n",
        "%%capture\n",
        "!pip install transformers\n",
        "import torch.nn as nn\n",
        "from transformers import AutoConfig\n",
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "from math import sqrt\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AXa_bnL362B4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utilities regarding the model and tokenizer\n",
        "model_ckpt = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ],
      "metadata": {
        "id": "wSLLULk_8Njh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The text we want to analyze\n",
        "text = 'time flies like an arrow'\n",
        "# We want to implement the first step of the tranformer model where we find\n",
        "# Q, K, V \n",
        "\n",
        "inputs = tokenizer(text, return_tensors='pt', add_special_tokens=False)\n",
        "# Each token is mapped to an ID in the tokenizer vocabulary.\n",
        "# We will then use an nn.embedding layer that will transform each token to \n",
        "# a 768 dimension vector.                                                   \n",
        "print(inputs.input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dYo-9eF6XIe",
        "outputId": "a9f35430-4b70-44b4-98c8-34e8047737b6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2051, 10029,  2066,  2019,  8612]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = AutoConfig.from_pretrained(model_ckpt)\n",
        "token_emb = nn.Embedding(config.vocab_size, config.hidden_size)\n",
        "token_emb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBfRHB8G77Nm",
        "outputId": "77cd140f-43da-4329-9d90-0e702c93b85d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(30522, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch = 1, 5 token, each token is a 768 dimensional vector\n",
        "# (batch_size, seq_len, hidden_dim)\n",
        "input_embeds = token_emb(inputs.input_ids)\n",
        "input_embeds.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NANZYFWtGg6",
        "outputId": "14178b11-3ac4-4ce3-8b93-ec43da498d31"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = key = value = input_embeds\n",
        "# should be equal to 768\n",
        "dim_k = key.size(-1)\n",
        "\n",
        "# torch.transpose(input, dim0, dim1)\n",
        "# The first dimension is the batch, that is why we dont transpose it.\n",
        "# Usually we have weight matrices Wq,k,v applied to the embeddings.\n",
        "# (5, 768) * (768, 5) = (5, 5)\n",
        "scores = torch.bmm(query, key.transpose(1,2))/sqrt(dim_k)\n",
        "scores.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-dN2lcytVdW",
        "outputId": "6a49081c-96da-4f27-cf0b-1c9ce69af69f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check wich type of matrix\n",
        "# output z will be a symmetric matrix\n",
        "x = torch.rand(3,5)\n",
        "z = torch.mm(x, x.transpose(0,1))\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2364xnUuD7N",
        "outputId": "f627d5e1-9930-42f4-e20f-4133a4b1bbc7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3.1543, 1.4546, 1.5078],\n",
            "        [1.4546, 0.7140, 0.7770],\n",
            "        [1.5078, 0.7770, 1.1728]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we have to normalize by applying softmax so the sum over each column\n",
        "# Equal to one\n",
        "# the dimension should be the last one as our weights are stored there. \n",
        "weights = F.softmax(scores, dim = -1)\n",
        "\n",
        "# Now we will multiply the attention weights by the values\n",
        "# The aim is to reach the dimensionality of the input\n",
        "attention_out = torch.bmm(weights, value)\n",
        "attention_out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ixxkx68vU2T",
        "outputId": "190a8892-dadd-4a1e-a1b2-169ef324ba8a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's turn all this into a function we can use later\n",
        "\n",
        "def scaled_attn_dot_product(q, k, v) -> torch.Tensor:\n",
        "  dim_k = query.size(-1)\n",
        "  scores = torch.bmm(q, k.transpose(1,2))/sqrt(dim_k)\n",
        "  weights = F.softmax(scores, dim=-1)\n",
        "  out = torch.bmm(weights, v)\n",
        "  return out"
      ],
      "metadata": {
        "id": "uluD0dFeqDYw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multiheaded attention will allow the self-attention layer to focus on different \n",
        "# semantic aspects of the sequence\n",
        "# We will apply three independent linear transformations to each embedding(q, k, v)\n",
        "# They will all carry their own set of learnable parameters\n",
        "# Don't forget nn.Linear only applies: y = torch.mm(x,transpose(A)) + b\n",
        "# The A matrix will contain parameters we can learn!\n",
        "\n",
        "class attention_head(nn.Module):\n",
        "  def __init__(self,embed_dim, head_dim):\n",
        "    super().__init__()\n",
        "    # Embedding dimensions = 768\n",
        "    self.q = nn.Linear(embed_dim, head_dim)\n",
        "    self.k = nn.Linear(embed_dim, head_dim)\n",
        "    self.v = nn.Linear(embed_dim, head_dim)\n",
        "  \n",
        "  def forward(self, hidden_state):\n",
        "    att_out = scaled_attn_dot_product(self.q(hidden_state),self.k(hidden_state),\n",
        "                                      self.v(hidden_state))\n",
        "    return att_out\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cNUeM7KHq7g-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class multiheaded_attention(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    embed_dims = config.hidden_size\n",
        "    num_heads = config.num_attention_heads\n",
        "    # In BERT they used 768/12\n",
        "    head_dim = embed_dims // num_heads\n",
        "    self.heads = nn.ModuleList([attention_head(embed_dims, head_dim)\n",
        "      for _ in range(num_heads)])\n",
        "  \n",
        "    self.out_linear = nn.Linear(embed_dims, embed_dims)\n",
        "\n",
        "  def forward(self, hidden_state):\n",
        "    x = torch.cat([h(hidden_state) for h in self.heads], dim=-1)\n",
        "    x = self.out_linear(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "kKDgbb92wTk5"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multiheaded_attention = multiheaded_attention(config)\n",
        "attn_out = multiheaded_attention(input_embeds)\n",
        "# 5 tokens each with a dimensionality of config.hidden_size\n",
        "attn_out.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44KRPddjy0x2",
        "outputId": "5b7d09d0-7768-492b-e421-900fc3afe35e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oo4IFCdUzkwy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}